重要的事先說在前 別真的買AMD顯卡來跑DL 使用Radeon VII跑tensorflow與pytorch純粹測試 購買Radeon VII的正確理由應該是 有OpenCL的程式要執行 且需要雙精度算力 而不需要ECC 又買不起計算卡(P100 V100) 這時才考慮收一張Radeon VII來應付 === 做實驗要有對照 因此使用同為8C16T的9900K作為3700X的對手 但不是專業評測媒體 沒有很多備品與時間 很難做到完全公平測試 只能盡量說明細節 讀者可自行判斷結果 測試目標是在盡量預設(官方Turbo)的條件下 用一些比較簡單的小程式 嘗試反應跑運算的能力(ML DL) 所有結果僅供參考 在windows上也能跑出類似的數據 有相同配備的人可以試著重現實驗結果 === 測試硬體 AMD Ryzen 7 3700X Wraith Prism (H mode) ASUS TUF GAMING X570PLUS 4x Kingston KVR32N22D8/16 HIS Radeon VII XPG SX8200Pro 1TB 全漢 聖武士 650W 視博通 聖鬥神 PRO Intel Core i99900K Thermalright Silver Arrow IBE Extreme GIGABYTE Z390 AORUS ELITE 4x KLEVV KD4AGU88C26N190A GIGABYTE RTX 2080 Ti Turbo XPG SX8200Pro 1TB 全漢 聖武士 650W 全漢 CMT240(B) 炫鬥士 (黑) 另外加測同一張2080ti插到3700x那台上 === BIOS版本與設定 TUF GAMING X570 PLUS 1405 PBO manual Package Power Tracking(PPT) 1000W Thermal Design Current(TDC) 1000A Electrical Design Current(EDC) 1000A 其餘預設 DDR43200 (222222) 1.2V Z390 AORUS ELITE F8 Package Power Limit 1 4090W Package Power Limit Time 1 127s Package Power Limit 2 4090W Package Power Limit Time 2 127s Platform Power Limit 1 4090W Platform Power Limit Time 1 127s Platform Power Limit 2 4090W Power Limit 3 4090W Power Limit 3 Time 127s Core Current Limit 255A 其餘預設 DDR42666 (191919) 1.2V (早期的科賦原生記憶體是有xmp的 開了時序會收緊 但這批比較後期 xmp profile時序是一樣的 開xmp就只是電壓變1.35V CPU更耗電) 另外使用 nvidiasmi pm 1 nvidiasmi pl 280 解除2080ti到280W OS Ubuntu Server 20.04 LTS kernel 5.4.026 ROCm driver 5.4.8 CUDA driver 440.64 頻率溫度功耗 數字皆為約略 詳細可看錄影 3700x sensors讀取溫度 turbostat讀取頻率瓦數 Radeon VII rocmsmi讀取溫度頻率瓦數 9900k turbostat讀取溫度頻率瓦數 2080ti nvidiasmi讀取溫度頻率瓦數 待機 3700xRadeon VII CPU 2100MHz 36度C 13W GPU 808MHz 36度C 18W 延長線 52W 3700x2080ti CPU 2100MHz 36度C 13W GPU 300MHz 31度C 6W 延長線 46W 9900k2080ti CPU 800MHz 28度C 8W GPU 300MHz 29度C 5W 延長線 38W Prime95 Version 29.8 build 6 Small FFTs(L1/L2/L3) FMA3(AVX2) 3700x 1秒 CPU 3978MHz 81.5度C 143W 延長線 210W 1分鐘 CPU 3911MHz 87.1度C 133W 延長線 197W https://youtu.be/FsxKta8cYQs 9900k 1秒 CPU 4700MHz 87度C 222W 延長線 314W 1分鐘 CPU 4532MHz 100度C 216W 延長線 290W https://youtu.be/1SJ_f3upgEc (linux的行為與windows不同 使用sudo service thermald stop 避免一撞溫度牆就降到base) (實驗室5顆9900k 1顆在ASUS PRIME Z390A上解除電流限制(192A)會自動關機 估計是VRM不夠力 另外4顆在GIGABYTE Z390 AORUS ELITE上 有1顆預設電壓較低 可90度上下全核4.7 其他3顆都只能100度全核4.5 也無法降電壓 就算只0.05V p95一樣無法過 只能說是體質問題 下面的效能測試是全核4.5GHz這粒CPU的結果) tensorflow resnet50 training fp16 batch128 3700xRadeon VII 1分鐘 GPU 1801MHz 105度C 273W 延長線 381W https://youtu.be/xBZvnZ0Gtk0 3700x2080ti 1秒 GPU 1905MHz 40度C 254W 延長線 351W 1分鐘 GPU 1845MHz 70度C 273W 延長線 366W https://youtu.be/7dURoFoTyY 9900k2080ti 1秒 GPU 1920MHz 39度C 254W 延長線 358W 1分鐘 GPU 1830MHz 69度C 279W 延長線 336W https://youtu.be/y3jh_HDrJg (真正跑數小時到數天的運算 基本上是穩定1545MHz 84度C) p95tensorflow 3700xRadeon VII CPU 125W GPU 302W 延長線 505W https://youtu.be/vXGoWQZyf5M 3700x2080ti CPU 129W GPU 279W 延長線 490W https://youtu.be/EjuvHMI8pQE 9900k2080ti CPU 228W GPU 270W 延長線 618W https://youtu.be/eVz76K0rsdE 由於現在CPU GPU都有boost 跑出來結果會飄 大概前幾位數比較一下趨勢就好 沒有重複很多次或固定溫度 不要太認真比較小數點後幾位 CPU理論效能測試 使用 https://github.com/Mysticial/Flops 86d412c (這結果會與AIDA64 GPGPU效能測試中的CPU結果相似) version3/binarieslinux下 ./2006Core2 //使用SSE2 模擬 一般/普通/傳統/上古遺跡 應用程式 ./2013Haswell //使用AVX/FMA3 模擬 高度最佳化的現代應用程式 (3700x執行./2017Zen不會有明顯差別) 128bit SSE2 256bit AVX 256bit FMA3 Multiply Add Multiply Add Fused Multiply Add 1T 16T 1T 16T 1T 16T 3700x 42.432 521.184 82.176 992.256 136.896 1044.1 9900k 39.072 301.008 79.968 602.016 159.552 1204.22 單位: GFlops 以上是單精度 zen2已經解決zen1 256bit浮點半速問題 zen2與skylake的架構分析文 網路上很多 兩家的解碼執行策略不同 導致這個結果 CPU計算效能測試 使用intel的測試script 基本反應numpy scipy sklearn效能 同時也可以知道像MATLAB與其他用到BLAS、LAPACK的程式會是什麼狀況 python使用Anaconda32020.02 內建numpy使用Intel MKL 另外比較numpy使用conda提供的OpenBLAS pip的OpenBLAS 與自編譯BLISlibFLAME有沒有機會贏MKL === 主程式 git clone nocheckout https://github.com/IntelPython/ibench.git cd ibench git checkout d2a81d04352427437e6e383654cfbd36e99c5ae9 python m ibench run b all size small runs 3 file result.json 強制MKL使用AVX2 export MKL_DEBUG_CPU_TYPE=5 切換OpenBLAS (註: 若用pip install numpy安裝pypi版也會是openblas) conda remove mkl numpy scipy scikitlearn numexpr conda install nomkl numpy scipy scikitlearn numexpr export OPENBLAS_NUM_THREADS=8 // numpy==1.18.1 scipy==1.4.1 BLISlibFLAME conda remove nomkl numpy scipy scikitlearn numexpr sudo apt install gfortran git clone https://github.com/flame/blis.git b 0.7.0 cd blis ./configure enablecblas enablethreading=openmp x86_64 make j (nproc) sudo make install cd .. git clone https://github.com/flame/libflame.git b 5.2.0 cd libflame ./configure enabledynamicbuild \ enablelapack2flame \ enablemultithreading=openmp \ enablesupermatrix \ enablemaxarglisthack make j (nproc) sudo make install cd .. git clone https://github.com/numpy/numpy.git b v1.17.2 cd numpy create site.cfg [blis] libraries = blis library_dirs = /usr/local/lib include_dirs = /usr/local/include/blis runtime_library_dirs = /usr/local/lib [flame] libraries = flame library_dirs = /usr/local/lib runtime_library_dirs = /usr/local/lib NPY_BLAS_ORDER=blis NPY_LAPACK_ORDER=flame python setup.py bdist_wheel pip install dist/numpy1.17.2cp37cp37mlinux_x86_64.whl cd .. git clone https://github.com/scipy/scipy.git b v1.1.0 cd scipy cp ../numpy/site.cfg . NPY_BLAS_ORDER=blis NPY_LAPACK_ORDER=flame python setup.py bdist_wheel pip install dist/scipy1.1.0cp37cp37mlinux_x86_64.whl export BLIS_NUM_THREADS=8 === CholeskyDet Dot Fft Inv Lu Qr Svd 9900k mkl 351.32456.52497.805.73337.58409.80262.106.49 pip 399.44444.85486.184.97295.99409.00103.186.19 3700x mkl 334.89393.53382.965.26249.74353.86234.548.06 debug mkl 403.91427.24444.156.32357.66384.55275.218.92 nomkl 288.64331.38329.635.24252.08309.60110.136.10 pip 363.68418.34428.935.06309.44391.73118.286.35 BLISFLAME 342.64298.42413.027.14227.18283.95116.600.75 單位: GFlops IO測試 使用fio 參數比照CrystalDiskMark 7 fio loops=5 size=1g runtime=5 \ time_based=1 stonewall direct=1 group_reporting \ name=SeqQ8T1read bs=1048576 iodepth=8 rw=read \ name=SeqQ8T1write bs=1048576 iodepth=8 rw=write \ name=SeqQ1T1read bs=1048576 iodepth=1 rw=read \ name=SeqQ1T1write bs=1048576 iodepth=1 rw=write \ name=4kQ32T16read bs=4096 iodepth=32 numjobs=16 rw=randread \ name=4kQ32T16write bs=4096 iodepth=32 numjobs=16 rw=randwrite \ name=4kQ1T1read bs=4096 iodepth=1 rw=randread \ name=4kQ1T1write bs=4096 iodepth=1 rw=randwrite 3700x 9900k 1MSeqQ8T1r2785MB/s 2781MB/s 1MSeqQ8T1w2845MB/s 1824MB/s 1MSeqQ1T1r2793MB/s 2858MB/s 1MSeqQ1T1w2818MB/s 1757MB/s 4kQ32T16r 697MB/s(170k) 657MB/s(160k) 4kQ32T16w 1497MB/s(365k) 1390MB/s(339k) 4kQ1T1r 80.0MB/s(19.5k) 61.2MB/s(14.9k) 4kQ1T1w 239MB/s(58.3k) 324MB/s(79.2k) (可能原因有 3700x直連cpu 9900k是pch 9900k是使用一陣子的舊ssd 但執行fstrim後速度差不多 沒有提升 若套用 https://makelinuxfastagain.com 會變快 但寫入還是一段差距 或者被換料了? 我沒有檢查顆粒是否相同) Tensorflow測試 使用官方benchmark resnet50 Radeon VII的docker image為rocm/tensorflow:rocm3.1tf2.1python3 2080ti為nvcr.io/nvidia/tensorflow:20.02tf2py3 === https://github.com/tensorflow/benchmarks aef6daa python scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \ data_format=NHWC batch_size=64 num_batches=100 \ model=resnet50 optimizer=sgd variable_update=replicated \ use_fp16=False distortions=False local_parameter_device=gpu \ num_gpus=1 display_every=10 === resnet50 fp32batch64fp32batch128fp16batch64fp16batch128fp16batch256 3700x 鐳7 282.96 292.60 390.69 423.17 443.81 3700x 2080ti 313.08 298.43 717.52 778.22 723.40 9900k 2080ti 306.34 294.64 696.98 752.51 706.08 單位images/sec Pytorch 與 混精度AMP(Apex) 測試 使用Transformers 2.8.0 BERT 取第三個epoch的時間 Radeon VII的docker image為rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch 2080ti為nvcr.io/nvidia/pytorch:20.02py3 === sudo apt install cabextract wget https://download.microsoft.com/download/D/4/6/ D46FF87AF6B94252AA8B3604ED519838/MSRParaphraseCorpus.msi mkdir MRPC cabextract MSRParaphraseCorpus.msi d MRPC cat MRPC/_2DEC3DBE877E4DB192D17C0256E90F1D tr d \r > MRPC/msr_paraphrase_train.txt cat MRPC/_D7B391F9EAFF4B1B8BCE8F21B20B1B61 tr d \r > MRPC/msr_paraphrase_test.txt rm MRPC/_ rm MSRParaphraseCorpus.msi wget https://gist.githubusercontent.com/W4ngatang/ 60c2bdb54d156a41194446737ce03e2e/raw/ 17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py python download_glue_data.py path_to_mrpc MRPC git clone https://github.com/huggingface/transformers.git b v2.8.0 cd transformers pip install . pip install r ./examples/requirements.txt export GLUE_DIR=../glue_data export TASK_NAME=MRPC python ./examples/run_glue.py \ model_type bert \ model_name_or_path bertbaseuncased \ task_name TASK_NAME \ do_train \ do_eval \ do_lower_case \ data_dir GLUE_DIR/TASK_NAME \ max_seq_length 128 \ per_gpu_eval_batch_size=8 \ per_gpu_train_batch_size=8 \ learning_rate 2e5 \ num_train_epochs 3.0 \ output_dir /tmp/TASK_NAME/ \ fp16 === bert fp32 fp16 3700x RadeonVII 00:52.901:56.8 3700x 2080ti 00:38.600:30.6 9900k 2080ti 00:38.500:31.8 單位為時間秒 Pytorch的混精度套件Apex是nvidia的 用在Radeon上因某些功能需要nvcc所以不能用 相容性也不好 從結果得知開了更慢 Radeon顯卡跑DL 若手上已有RX 400/500 8GB 時間很多的話可以折騰玩玩看 ML套件有支援OpenCL (像LightGBM) 也可以加速 但該買NVIDIA還是得買 這沒辦法 3600x/3700x/9600K(F)/9700K(F) 這幾顆就看預算與需求下去考量 要省錢就3600x/3700x intel還要加散熱器 (原廠散熱只保證base) 但若不需要GPU AMD也是要加亮機卡 只要內顯 換不了openblas 需要用到多核MKL的保守派 選intel (畢竟無法保證intel會不會某天就把MKL_DEBUG_CPU_TYPE給砍了 速度慢就算了 相容性是一個問題 要是程式完全無法執行會很頭痛) Radeon VII的溫度限制是110度 要頂到才會降頻 功耗測試那邊沒有特別調整風扇或溫度限制 鐳7就是RadeonVII。7nm的八核心跑輸14nm的八核心 笑死。樓上又要發作了？。已經發作了。整天一直在崩潰 笑死。推詳細測試。推測試分享。。推所配的power，真正物有所值。感謝分享 非常有幫助。測試詳細 讚。推詳細測試。resnet50訓練那邊 radeon 105度？ 是關了降頻嘛？。一直對他16GB ram感覺有興趣 但網路上資料好少 感謝。提供測試結果。另外 最後表格的鐳7那個是vii？。印象tf在batch norm好像會把fp16轉回fp32算再弄回去。fp16 如果都fp16 搞不好2080ti又更快 自用搞不好兩。張2070寫multi gpu還比RadeonVII好？ 再次感謝測試。fp16這部分對我來說很重要XD。所以結論是3700x跟9900k跑起來差不多嗎0.0?